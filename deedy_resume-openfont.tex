\documentclass[]{deedy-resume-openfont}
\usepackage{graphicx}
\usepackage{xcolor}
\graphicspath{ {./images/} }
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\usepackage{fontspec}
%\setmainfont{JetBrains Mono}

\begin{document}

\namesection{Abhineet Kumar}{Sinha}{{Senior Data Engineer} | \includegraphics{images/SLB.png} {Schlumberger} | \includegraphics{images/GE.png} {Ex-GE} | \includegraphics{images/RIL.png} {Ex-RIL} | {IIT (ISM) Dhanbad}\\
{Mumbai, Maharashtra, India} | {Total Exp: 8 yrs}\\
{\small{abhineet.sinha1992@gmail.com} | {Mob.:  08809628590} | {Linkedin:}
\color{blue}
\href{https://www.linkedin.com/in/abhineet-kumar-sinha-8122262b}{https://www.linkedin.com/in/abhineet-kumar-sinha-8122262b}}
}
\begin{minipage}[t]{0.37\textwidth} 

    
\section{Skills} 

\textbf{
\includegraphics{images/bullet1.png} Data Warehousing
\includegraphics{images/bullet1.png} Talend \\
\includegraphics{images/bullet1.png} Data Lake Storage
\includegraphics{images/bullet1.png} Azure Data Factory
\includegraphics{images/bullet1.png} Hadoop Batch and Realtime Data Pipelines
\includegraphics{images/bullet1.png} Spark
\includegraphics{images/bullet1.png} Databricks
\includegraphics{images/bullet1.png} Scala/Java
\includegraphics{images/bullet1.png} Azure Data Paltforms
\includegraphics{images/bullet1.png} Kafka
\includegraphics{images/bullet1.png} Azure Stream Analytics
\includegraphics{images/bullet1.png} ETL performance tuning
\includegraphics{images/bullet1.png} Advanced SQL programming
\includegraphics{images/bullet1.png} Snowflake
\includegraphics{images/bullet1.png} Powershell
\includegraphics{images/bullet1.png} PySpark
\includegraphics{images/bullet1.png} Spark SQL
\includegraphics{images/bullet1.png} Data Modelling Tools
\includegraphics{images/bullet1.png} Azure PaaS Services
\includegraphics{images/bullet1.png} Power BI
\includegraphics{images/bullet1.png} Python/R
\includegraphics{images/bullet1.png} DevOps
\includegraphics{images/bullet1.png} CI/CD
\includegraphics{images/bullet1.png} Jenkins
\includegraphics{images/bullet1.png} Git/Gitlab
\includegraphics{images/bullet1.png} Agile/Scrum
}

\sectionsep
\section{Licenses And Certifications}
\vspace{\topsep} % Hacky fix for awkward extra vertical space
\begin{tightemize}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]Architecting Big Data Applications: Batch Mode Application
    \color{blue}
    \subitem \small {Issued Sep 2021}
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]Azure Administration Essential Training
\subitem \small {Issued Oct 2021}
%\vspace{}\color[grey]\small Issued
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]Big Data Analytics with Hadoop and Apache Spark
\subitem \small {Issued Oct 2020}
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]Dataiku Advanced Designer
    \color{blue}
    \subitem \small {Issued Oct 2020}
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]Dataiku ML Practitioner
    \color{blue}
    \subitem \small {Issued Oct 2020}
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]TCA-TIBCO Spotfire
    \color{blue}
    \subitem \small {Issued Aug 2022}
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]AWS Essential Training for Architects
    \color{blue}
    \subitem \small {Issued Sep 2021}
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]Dataiku ML practitioner
    \color{blue}
    \subitem \small {Issued Oct 2021}
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]Cloud Architecture: Advanced Concepts 
    \color{blue}
    \subitem \small {Issued Apr 2019}
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]Mastering Microservices with Java
    \color{blue}
    \subitem \small {Issued Sep 2021}
\vspace{5 pt}
\item[{\includegraphics[scale=0.05]{images/Untitled.png}}]Neural Networks and Convolutional Neural Networks Essential Training
    \color{blue}
    \subitem \small {Issued Sep 2021}
\end{tightemize}

\end{minipage} 
\hfill
\begin{minipage}[t]{0.60\textwidth} 

\section{CAREER OBJECTIVE}
Data driven software engineer with around 8 years of experience in data sciences and data engineering. Highly analytical and process oriented data analyst with indepth knowledge of database types; research methodologies; and big data capture, curation,
manipulation and visualization.
Furnish insights, analytics and
business intelligence used to
advance opportunity
identification, process
reengineering and corporate
growth

\section{EXPERIENCE}
\runsubsection{Schlumberger}
\descript{| Senior Data Engineer }
\location{Oct 2021 - Present | Pune, India}
\sectionsep

\hspace{\topsep} % Hacky fix for awkward extra vertical space
\begin{tightemize}
\item Provided technical leadership and hands on implementationin areas of data techniques including data access, integration, modelling, visualization and implementation.
\item Design and build data processing pipelines using tools and
frameworks in the Hadoop ecosystem.
\item Design and build ETL pipelines to automate ingestion of
structured and unstructured data.
\item Working on data warehousing and data lake and integration
with legacy platforms.
\item very strong understanding and experience with Java, Scala, GoLang and Python
\item Master data management, integration , flow and mapping from
as-is to to-be systems.
\item Design and Build pipelines to facilitate data analysis, data
modelling and building ETL pipelines.
\item Proficiency in programming language - Python, Java, or Scala
\item Working in Big Data Ecosystem with experience in Java,
Hadoop, Spark, Snowflake, Cassandra and NoSQL.
\item Working with distributed architecture and MPP engine (Spark,
Impala etc.)
\item Building scalable and highly available distributed systems in production.
\item Implementation of CI/CD (Jenkins, Maven), Log aggregation/Monitoring/alerting for production
system.
\item Experience on Azure and AWS as PaaS.
\end{tightemize}

\vspace{\topsep}
\runsubsection{GE Oil \& Gas}
\descript{| Data Engineer }
\location{Dec 2020 - Oct 2021 | Bangalore, India}
\sectionsep
\begin{tightemize}
\item Design and build data processing pipelines using tools and
frameworks in the Hadoop ecosystem.
\item Responsible for building and maintaining data architecture and batch/stream data loads for wide-scale customer reporting platform.
\item Deployment of ETL load stack on Linux based on-prem enterprise grade servers.
\item Creating batch and realtime data pipelines on Azure Data Platform using Logic Apps, Automation Run Books, Azure Data Factory, Azure Databricks, Azure Event Hub, Kafka, Azure Stream Analytics. 
\item Performance tuning of complex ETL mappings of relational and non-relational workloads.
\item Advanced SQL programming on SparkSQL, PySpark, PL/SQL or T-SQL.
% \item Facilitate data integration, data conformity, data integrity and ensure data structures are designed for flexibility to support future business needs and enhancements.
\end{tightemize}

\end{minipage}

\begin{minipage}[t]{1\textwidth} 
\begin{tightemize}
\item Unix scripting and Power shell scripting for Azure PaaS Services.
\end{tightemize}
\vspace{\topsep}
\runsubsection{Reliance Industries Limited}
\descript{| Data Engineer }
\location{Apr 2015 - Dec 2019 | Mumbai, India}
\sectionsep
\begin{tightemize}
\item Big Data, Data Analytics, Data Lake ETL experience using Spark scripting, AWS EMR, AWS Redshift,
AWS S3, AWS EC2, AWS CloudWatch, AWS IAM, Microsoft SQL, Microsoft SSIS, Java, GitLab,
DevOps (CI/CD).
\item Handle old and new SSIS jobs related to new Procurement Data Warehouse (PDW), code changes and
issue resolution.
\item Code management tools (Git/GitHub).
\item Cloud deployments of BI solutions including use of AWS eco-systems.
\item Experience with SQL-on-Hadoop technology (Hive, Impala, Spark SQL, and Presto).
\end{tightemize}
\vspace{\topsep}
\runsubsection{Reliance Industries Limited}
\descript{| IT-Business Analyst }
\sectionsep
\begin{tightemize}
\item Develop business architecture using requirements such as scope, processes, alternatives, and risks.
\item Derive meaningful insights after creating and validating Data Model using ML and explain the
business value to senior management.
\item Building end to end models related to Forecasting, Optimization Models. Etc.
\item Evaluating and defining key metrics.
\item Automating analyses and authoring pipelines via SQL and Python-based framework.
\item Interface with multiple stakeholders and understand business requirements and develop and
implement best in class analytics solutions.
\item Develop analytical models for enterprise asset management, for MIS reporting and project/shutdown planning, budget planning/allocation and cost reports.
\item Create various algorithms for asset performance optimization, predictive analysis and develop
solutions based on insights captured from data.
\item Data analysis and insights deduction based on perusing of enterprise production data.
\item Structure concise reports with insights supported by solid analytics and logical thinking.
\item Translate business requirements into tangible solutions specifications and high quality, on time
deliverables.
\item Conducted data mining, data modeling and statistical analysis to develop suitable simulation models for optimizing production facilities and process reengineering to drive production, enhance system reliability and eliminate production bottlenecks.
\end{tightemize}

\location{PROJECTS:}

\begin{tightemize}
\item Develop and implement a machine learning model to predict equipment/process failure based on
historical data and propose corrective action beforehand to mitigate asset breakdown.
\item Using clustering algorithm to classify multivariate data sets related to equipment to train data and develop model to predict incident of equipment failure based on the learned data.
\item A 15% reduction in facility failure cases, resulting in achieving 1 MMSCMD gas production.
\item Improved production forecasting that reduced deviation from actual production by 17%
\item Plant-wide optimization model to de-bottleneck process units to maximize profit.
\end{tightemize}

\end{minipage}
 \end{document}  \documentclass[]{article}
